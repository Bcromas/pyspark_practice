{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here our goal is to create a model to predict the number of crew members needed to staff a given cruise ship. We'll explore the data, perform some pre-processing, create a train-test split, and then evaluate a number of models including ridge and LASSO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/home/bryan/Documents/Code/spark-2.4.5-bin-hadoop2.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('lr_crew_size').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(\"data/cruise_ship_info.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ship_name: string (nullable = true)\n",
      " |-- Cruise_line: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tonnage: double (nullable = true)\n",
      " |-- passengers: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- cabins: double (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data.count() == data.na.drop().count(), \"Check for missing data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### There are no NaN values in the given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "|  Ship_name|Cruise_line|Age|           Tonnage|passengers|length|cabins|passenger_density|crew|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "|    Journey|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
      "|      Quest|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
      "|Celebration|   Carnival| 26|            47.262|     14.86|  7.22|  7.43|             31.8| 6.7|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(data.select('Ship_name').distinct().count()/data.count(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Ship_name is essentially a unique value, 87% of records have a unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(data.select(\"Cruise_line\").distinct().count()/data.count(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Cruise_line is much less distinct, 13% of records have a unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these_features = data.columns[1:-1] # grab features\n",
    "# these_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we'll leave out Ship_name since it's essentially a unique value and we won't use it in our initial models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'crew'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_target = data.columns[-1] # the target\n",
    "this_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/test split & pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/test split\n",
    "train_data,test_data = data.randomSplit([0.8,0.2],7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data.count()*0.75 < train_data.count() < data.count()*0.8, \"Check output of randomSplit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> StringIndexer ~ LabelEncoder in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol='Cruise_line', outputCol='Cruise_line_index', handleInvalid='keep')\n",
    "fitted_indexer = indexer.fit(train_data)\n",
    "\n",
    "train_data = fitted_indexer.transform(train_data)\n",
    "test_data = fitted_indexer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------------+\n",
      "|      Cruise_line|avg(Cruise_line_index)|\n",
      "+-----------------+----------------------+\n",
      "|         Carnival|                   0.0|\n",
      "|         Princess|                   1.0|\n",
      "|  Royal_Caribbean|                   2.0|\n",
      "| Holland_American|                   3.0|\n",
      "|        Norwegian|                   4.0|\n",
      "|            Costa|                   5.0|\n",
      "|        Celebrity|                   6.0|\n",
      "|              MSC|                   7.0|\n",
      "|             Star|                   8.0|\n",
      "|              P&O|                   9.0|\n",
      "|Regent_Seven_Seas|                  10.0|\n",
      "|          Oceania|                  11.0|\n",
      "|         Windstar|                  12.0|\n",
      "|          Azamara|                  13.0|\n",
      "|           Disney|                  14.0|\n",
      "|        Silversea|                  15.0|\n",
      "|         Seabourn|                  16.0|\n",
      "|          Crystal|                  17.0|\n",
      "+-----------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.groupBy(\"Cruise_line\").avg('Cruise_line_index').sort(\"avg(Cruise_line_index)\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The above is a crude way of visualizing the mapping created by StringIndexer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoderEstimator(inputCols=['Cruise_line_index'],\n",
    "                                 outputCols=['Cruise_line_index_1hot'],\n",
    "                                handleInvalid='keep')\n",
    "\n",
    "fitted_encoder = encoder.fit(train_data)\n",
    "train_data = fitted_encoder.transform(train_data)\n",
    "test_data = fitted_encoder.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+---+-------+----------+------+------+-----------------+----+-----------------+----------------------+\n",
      "|Ship_name|     Cruise_line|Age|Tonnage|passengers|length|cabins|passenger_density|crew|Cruise_line_index|Cruise_line_index_1hot|\n",
      "+---------+----------------+---+-------+----------+------+------+-----------------+----+-----------------+----------------------+\n",
      "|  Allegra|           Costa| 21|  28.43|      8.08|  6.16|   4.1|            35.19| 4.0|              5.0|        (19,[5],[1.0])|\n",
      "|Amsterdam|Holland_American| 13|   61.0|      13.8|   7.8|  6.88|             44.2| 6.0|              3.0|        (19,[3],[1.0])|\n",
      "|  Arcadia|             P&O|  9|   85.0|     19.68|  9.35|  9.84|            43.19|8.69|              9.0|        (19,[9],[1.0])|\n",
      "+---------+----------------+---+-------+----------+------+------+-----------------+----+-----------------+----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop('Cruise_line')\n",
    "test_data = test_data.drop('Cruise_line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'Cruise_line' not in train_data.columns and test_data.columns, \"Check 'Cruise_line' was dropped.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "these_features = train_data.columns\n",
    "[these_features.remove(i) for i in ['Ship_name','crew','Cruise_line_index']]; # remove elements in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols = these_features,\n",
    "    outputCol = \"features\")\n",
    "\n",
    "train_data = assembler.transform(train_data)\n",
    "test_data = assembler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+-------+----------+------+------+-----------------+----+-----------------+----------------------+----------------------------------------------------------+\n",
      "|Ship_name|Age|Tonnage|passengers|length|cabins|passenger_density|crew|Cruise_line_index|Cruise_line_index_1hot|features                                                  |\n",
      "+---------+---+-------+----------+------+------+-----------------+----+-----------------+----------------------+----------------------------------------------------------+\n",
      "|Allegra  |21 |28.43  |8.08      |6.16  |4.1   |35.19            |4.0 |5.0              |(19,[5],[1.0])        |(25,[0,1,2,3,4,5,11],[21.0,28.43,8.08,6.16,4.1,35.19,1.0])|\n",
      "|Amsterdam|13 |61.0   |13.8      |7.8   |6.88  |44.2             |6.0 |3.0              |(19,[3],[1.0])        |(25,[0,1,2,3,4,5,9],[13.0,61.0,13.8,7.8,6.88,44.2,1.0])   |\n",
      "|Arcadia  |9  |85.0   |19.68     |9.35  |9.84  |43.19            |8.69|9.0              |(19,[9],[1.0])        |(25,[0,1,2,3,4,5,15],[9.0,85.0,19.68,9.35,9.84,43.19,1.0])|\n",
      "+---------+---+-------+----------+------+------+-----------------+----+-----------------+----------------------+----------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(\n",
    "    featuresCol='features', \n",
    "    labelCol='crew', \n",
    "    predictionCol='prediction'\n",
    ") # NOT recommended to create unregularized linear model especially with small data\n",
    "\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(this_model):\n",
    "    \"\"\"\n",
    "    Print out select attributes of models.\n",
    "    \n",
    "    Args:\n",
    "        this_model - pyspark.ml model; a model that's been fitted to training data.\n",
    "    \n",
    "    Returns:\n",
    "        n/a - prints out attributes.\n",
    "    \"\"\"\n",
    "    this_summary = this_model.summary\n",
    "    \n",
    "    print(\"MAE: {}\".format(round(this_summary.meanAbsoluteError,5)))\n",
    "    print(\"r2: {}\".format(round(this_summary.r2,5)))\n",
    "    print(\"adjusted r2: {}\".format(round(this_summary.r2adj,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.416\n",
      "r2: 0.96863\n",
      "adjusted r2: 0.96047\n"
     ]
    }
   ],
   "source": [
    "print_results(lr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This could be overfitting since there's no regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.41553\n",
      "r2: 0.966\n",
      "adjusted r2: 0.95715\n"
     ]
    }
   ],
   "source": [
    "ridge = LinearRegression(\n",
    "    featuresCol='features', \n",
    "    labelCol='crew', \n",
    "    predictionCol='prediction', \n",
    "    regParam=0.1, \n",
    "    elasticNetParam=0.0\n",
    ")\n",
    "\n",
    "ridge_model = ridge.fit(train_data)\n",
    "print_results(ridge_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "signif_feats = [ridge_model.summary.pValues.index(i) for i in ridge_model.summary.pValues if i <= 0.05] # params at indices 1,3,& 4 are <= 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 4, 8, 14, 25]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ridge_model.summary.pValues\n",
    "\n",
    "signif_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [these_features[i] for i in signif_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0149, 0.0301, 0.0407, 0.5421, 0.2642, 0.0021, 0.1835, 0.0282, -1.2928, -0.5888, 0.6866, -0.2787, 0.5992, -0.002, 1.5227, -0.1426, 0.0797, 0.4983, -0.434, 0.1478, 0.4967, 0.0598, 0.2222, -0.0124, 0.0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ridge_model.coefficients[signif_feats]\n",
    "ridge_model.coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.49561\n",
      "r2: 0.95754\n",
      "adjusted r2: 0.94648\n"
     ]
    }
   ],
   "source": [
    "lasso = LinearRegression(\n",
    "    featuresCol='features', \n",
    "    labelCol='crew', \n",
    "    predictionCol='prediction', \n",
    "    regParam=0.1, \n",
    "    elasticNetParam=1\n",
    ")\n",
    "\n",
    "lasso_model = lasso.fit(train_data)\n",
    "print_results(lasso_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No p-value available for this LinearRegressionModel\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print([lasso_model.summary.pValues.index(i) for i in lasso_model.summary.pValues if i <= 0.05])\n",
    "except Exception as e:\n",
    "    print('No p-value available for this LinearRegressionModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0, 0.0194, 0.0, 0.4803, 0.4098, 0.0, 0.0, 0.0, -0.7495, -0.3421, 0.2685, 0.0, 0.2583, 0.0, 0.7255, 0.0, 0.0, 0.0, -0.0927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'Tonnage',\n",
       " 'passengers',\n",
       " 'length',\n",
       " 'cabins',\n",
       " 'passenger_density',\n",
       " 'Cruise_line_index_1hot']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "these_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Convert onehot array to string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-a4dd66fcc4f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Convert onehot array to string\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# https://www.hackdeploy.com/pyspark-one-hot-encoding-with-countvectorizer/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: Convert onehot array to string"
     ]
    }
   ],
   "source": [
    "raise ValueError(\"Convert onehot array to string\") # https://www.hackdeploy.com/pyspark-one-hot-encoding-with-countvectorizer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models with features 1, 3, & 4\n",
    "> ### Will a simpler model outperform the models using all features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_features = [these_features[i] for i in [1,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=few_features,\n",
    "    outputCol='few_features'\n",
    "    )\n",
    "\n",
    "train_data = assembler.transform(train_data)\n",
    "test_data = assembler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_lr = LinearRegression(\n",
    "    featuresCol='few_features', \n",
    "    labelCol='crew', \n",
    "    predictionCol='few_features_prediction'\n",
    ") # NOT recommended to create unregularized linear model especially with small data\n",
    "\n",
    "few_lr_model = few_lr.fit(train_data)\n",
    "print_results(few_lr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge (again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_ridge = LinearRegression(\n",
    "    featuresCol='few_features', \n",
    "    labelCol='crew', \n",
    "    predictionCol='few_features_prediction', \n",
    "    regParam=0.1, \n",
    "    elasticNetParam=0.0\n",
    ")\n",
    "\n",
    "few_ridge_model = few_ridge.fit(train_data)\n",
    "print_results(few_ridge_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO (again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_lasso = LinearRegression(\n",
    "    featuresCol='few_features', \n",
    "    labelCol='crew', \n",
    "    predictionCol='few_features_prediction', \n",
    "    regParam=0.1, \n",
    "    elasticNetParam=1\n",
    ")\n",
    "\n",
    "few_lasso_model = few_lasso.fit(train_data)\n",
    "print_results(few_lasso_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
