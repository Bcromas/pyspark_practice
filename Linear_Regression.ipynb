{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here our goal is to create a model to predict the number of crew members needed to staff a given cruise ship. We'll explore the data, perform some pre-processing, create a train-test split, and then evaluate a number of models including ridge and LASSO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/home/bryan/Documents/Code/spark-2.4.5-bin-hadoop2.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('lr_crew_size').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(\"cruise_ship_info.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ship_name: string (nullable = true)\n",
      " |-- Cruise_line: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tonnage: double (nullable = true)\n",
      " |-- passengers: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- cabins: double (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data.count() == data.na.drop().count(), \"Check for missing data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### There are no NaN values in the given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "|  Ship_name|Cruise_line|Age|           Tonnage|passengers|length|cabins|passenger_density|crew|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "|    Journey|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
      "|      Quest|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
      "|Celebration|   Carnival| 26|            47.262|     14.86|  7.22|  7.43|             31.8| 6.7|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(data.select('Ship_name').distinct().count()/data.count(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Ship_name is essentially a unique value, 87% of records have a unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(data.select(\"Cruise_line\").distinct().count()/data.count(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Cruise_line is much less distinct, 13% of records have a unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cruise_line',\n",
       " 'Age',\n",
       " 'Tonnage',\n",
       " 'passengers',\n",
       " 'length',\n",
       " 'cabins',\n",
       " 'passenger_density']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "these_features = data.columns[1:-1] # grab features\n",
    "these_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we'll leave out Ship_name since it's essentially a unique value and we won't use it in our initial models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'crew'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_target = data.columns[-1] # the target\n",
    "this_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/test split & pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/test split\n",
    "train_data,test_data = data.randomSplit([0.8,0.2],7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data.count()*0.75 < train_data.count() < data.count()*0.8, \"Check output of randomSplit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> StringIndexer ~ LabelEncoder in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol='Cruise_line', outputCol='Cruise_line_index', handleInvalid='keep')\n",
    "fitted_indexer = indexer.fit(train_data)\n",
    "\n",
    "train_data = fitted_indexer.transform(train_data)\n",
    "test_data = fitted_indexer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------------+\n",
      "|      Cruise_line|avg(Cruise_line_index)|\n",
      "+-----------------+----------------------+\n",
      "|         Carnival|                   0.0|\n",
      "|         Princess|                   1.0|\n",
      "|  Royal_Caribbean|                   2.0|\n",
      "| Holland_American|                   3.0|\n",
      "|        Norwegian|                   4.0|\n",
      "|            Costa|                   5.0|\n",
      "|        Celebrity|                   6.0|\n",
      "|              MSC|                   7.0|\n",
      "|             Star|                   8.0|\n",
      "|              P&O|                   9.0|\n",
      "|Regent_Seven_Seas|                  10.0|\n",
      "|          Oceania|                  11.0|\n",
      "|         Windstar|                  12.0|\n",
      "|          Azamara|                  13.0|\n",
      "|           Disney|                  14.0|\n",
      "|        Silversea|                  15.0|\n",
      "|         Seabourn|                  16.0|\n",
      "|          Crystal|                  17.0|\n",
      "+-----------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.groupBy(\"Cruise_line\").avg('Cruise_line_index').sort(\"avg(Cruise_line_index)\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The above is a crude way of visualizing the mapping created by StringIndexer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop('Cruise_line')\n",
    "test_data = test_data.drop('Cruise_line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'Cruise_line' not in train_data.columns and test_data.columns, \"Check 'Cruise_line' was dropped.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols = these_features[1:],\n",
    "    outputCol = \"features\")\n",
    "\n",
    "train_data = assembler.transform(train_data)\n",
    "test_data = assembler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+-------+----------+------+------+-----------------+----+-----------------+--------------------+\n",
      "|Ship_name|Age|Tonnage|passengers|length|cabins|passenger_density|crew|Cruise_line_index|            features|\n",
      "+---------+---+-------+----------+------+------+-----------------+----+-----------------+--------------------+\n",
      "|  Allegra| 21|  28.43|      8.08|  6.16|   4.1|            35.19| 4.0|              5.0|[21.0,28.43,8.08,...|\n",
      "|Amsterdam| 13|   61.0|      13.8|   7.8|  6.88|             44.2| 6.0|              3.0|[13.0,61.0,13.8,7...|\n",
      "|  Arcadia|  9|   85.0|     19.68|  9.35|  9.84|            43.19|8.69|              9.0|[9.0,85.0,19.68,9...|\n",
      "+---------+---+-------+----------+------+------+-----------------+----+-----------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(\n",
    "    featuresCol='features', \n",
    "    labelCol='crew', \n",
    "    predictionCol='prediction'\n",
    ") # NOT recommended to create unregularized linear model especially with small data\n",
    "\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(this_model):\n",
    "    \"\"\"\n",
    "    Print out select attributes of models.\n",
    "    \n",
    "    Args:\n",
    "        this_model - pyspark.ml model; a model that's been fitted to training data.\n",
    "    \n",
    "    Returns:\n",
    "        n/a - prints out attributes.\n",
    "    \"\"\"\n",
    "    this_summary = this_model.summary\n",
    "    \n",
    "    print(\"MAE: {}\".format(round(this_summary.meanAbsoluteError,5)))\n",
    "    print(\"r2: {}\".format(round(this_summary.r2,5)))\n",
    "    print(\"adjusted r2: {}\".format(round(this_summary.r2adj,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.58346\n",
      "r2: 0.94315\n",
      "adjusted r2: 0.94019\n"
     ]
    }
   ],
   "source": [
    "print_results(lr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This could be overfitting since there's no regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.61027\n",
      "r2: 0.93661\n",
      "adjusted r2: 0.9333\n"
     ]
    }
   ],
   "source": [
    "ridge = LinearRegression(\n",
    "    featuresCol='features', \n",
    "    labelCol='crew', \n",
    "    predictionCol='prediction', \n",
    "    regParam=0.1, \n",
    "    elasticNetParam=0.0\n",
    ")\n",
    "\n",
    "ridge_model = ridge.fit(train_data)\n",
    "print_results(ridge_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6089\n",
      "r2: 0.93752\n",
      "adjusted r2: 0.93426\n"
     ]
    }
   ],
   "source": [
    "lasso = LinearRegression(\n",
    "    featuresCol='features', \n",
    "    labelCol='crew', \n",
    "    predictionCol='prediction', \n",
    "    regParam=0.1, \n",
    "    elasticNetParam=1\n",
    ")\n",
    "\n",
    "lasso_model = lasso.fit(train_data)\n",
    "print_results(lasso_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
