{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A client wants to reduce customer churn by determining how reliably it can be predicted and intervening in situations wheew a client is likely to leave them. We'll use the data in customer_churn.csv to fit and evaluate a model and then generate predictions using the data in new_customers.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/home/bryan/Documents/Code/spark-2.4.5-bin-hadoop2.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('lr_churn').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(\"data/customer_churn.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Churn: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data.count() == data.na.drop().count(), \"Check for missing data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+\n",
      "|           Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|       Onboard_date|            Location|             Company|Churn|\n",
      "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+\n",
      "|Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|2013-08-30 07:00:40|10265 Elizabeth M...|          Harvey LLC|    1|\n",
      "|   Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|2013-08-13 00:38:46|6157 Frank Garden...|          Wilson PLC|    1|\n",
      "|     Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|2016-06-29 06:20:07|1331 Keith Court ...|Miller, Johnson a...|    1|\n",
      "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### According to the client, whether a client has an account manager or not is determined randomly. Can we see, based on the data, whether this random phenomenon has a positive or negative impact on churn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(data.select('Company').distinct().count()/data.count(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### The Company column is effectively a unique value and may not help us in predicting churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------+\n",
      "|Location                                               |\n",
      "+-------------------------------------------------------+\n",
      "|10265 Elizabeth Mission Barkerburgh, AK 89518          |\n",
      "|6157 Frank Gardens Suite 019 Carloshaven, RI 17756     |\n",
      "|1331 Keith Court Alyssahaven, DE 90114                 |\n",
      "|13120 Daniel Mount Angelabury, WY 30645-4695           |\n",
      "|765 Tricia Row Karenshire, MH 71730                    |\n",
      "|6187 Olson Mountains East Vincentborough, PR 74359     |\n",
      "|4846 Savannah Road West Justin, IA 87713-3460          |\n",
      "|25271 Roy Expressway Suite 147 Brownport, FM 59852-6150|\n",
      "|3725 Caroline Stravenue South Christineview, MA 82059  |\n",
      "|363 Sandra Lodge Suite 144 South Ann, WI 51655-7561    |\n",
      "+-------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('Location').show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### The locations appear to be U.S.-based. Would it be helpful to generate new State and/or Zip Code features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary| Onboard_date_year|\n",
      "+-------+------------------+\n",
      "|  count|               900|\n",
      "|   mean|2010.8011111111111|\n",
      "| stddev|3.2072288498508783|\n",
      "|    min|              2006|\n",
      "|    max|              2016|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.withColumn('Onboard_date_year', year('Onboard_date'))\n",
    "data.select('Onboard_date_year').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Onboard_date covers a period of approximately 10 years from 2006 to 2016. Below I will verify whether the columns Years and Onboard_date are internally consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn('Years_since_onboard', 2020-F.col('Onboard_date_year'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+\n",
      "|Years|Years_since_onboard|\n",
      "+-----+-------------------+\n",
      "| 7.22|                  7|\n",
      "|  6.5|                  7|\n",
      "| 6.67|                  4|\n",
      "| 6.71|                  6|\n",
      "| 5.56|                  4|\n",
      "+-----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(['Years', 'Years_since_onboard']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn('Years_diff', F.abs(col('Years')-col('Years_since_onboard')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+-------------------+\n",
      "|Years|Years_since_onboard|         Years_diff|\n",
      "+-----+-------------------+-------------------+\n",
      "| 7.22|                  7|0.21999999999999975|\n",
      "|  6.5|                  7|                0.5|\n",
      "| 6.67|                  4|               2.67|\n",
      "| 6.71|                  6|               0.71|\n",
      "| 5.56|                  4| 1.5599999999999996|\n",
      "+-----+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(['Years', 'Years_since_onboard', 'Years_diff']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+--------------------+\n",
      "|summary|            Years|Years_since_onboard|          Years_diff|\n",
      "+-------+-----------------+-------------------+--------------------+\n",
      "|  count|              900|                900|                 900|\n",
      "|   mean| 5.27315555555555|  9.198888888888888|   4.249177777777782|\n",
      "| stddev|1.274449013194616| 3.2072288498508783|   2.980322188381301|\n",
      "|    min|              1.0|                  4|0.009999999999999787|\n",
      "|    max|             9.15|                 14|               11.59|\n",
      "+-------+-----------------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(['Years', 'Years_since_onboard', 'Years_diff']).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
